{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Email Detector with Neural Network and BERT model\n",
    "## with ~99.3% Accuracy on 164K email sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import torch  \n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim \n",
    "from tqdm import tqdm \n",
    "from torch.utils.data import Dataset, DataLoader, random_split  \n",
    "from sklearn.metrics import classification_report, accuracy_score  \n",
    "from transformers import BertTokenizer, BertModel\n",
    "# from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from torch.cuda.amp import GradScaler, autocast   \n",
    "\n",
    "# Load the dataset  \n",
    "data = pd.read_csv(\"Data/FullDataset.csv\")  \n",
    "print(data.head())  \n",
    "\n",
    "# Preprocess the dataset   \n",
    "X = data[\"text\"].values  \n",
    "y = data[\"label\"].values  \n",
    "\n",
    "# Load tokenizer for Bert  \n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')   \n",
    "\n",
    "# Custom dataset class  \n",
    "class TextDataset(Dataset):  \n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):  \n",
    "        self.texts = texts  \n",
    "        self.labels = labels  \n",
    "        self.tokenizer = tokenizer  \n",
    "        self.max_length = max_length  \n",
    "\n",
    "    def __len__(self):  \n",
    "        return len(self.texts)  \n",
    "\n",
    "    def __getitem__(self, idx):  \n",
    "        encoding = self.tokenizer.encode_plus(  \n",
    "            self.texts[idx],   \n",
    "            add_special_tokens=True,   \n",
    "            max_length=self.max_length,   \n",
    "            padding='max_length',   \n",
    "            truncation=True,  \n",
    "            return_tensors='pt'  \n",
    "        )  \n",
    "\n",
    "        # Return tensor inputs and label  \n",
    "        return {  \n",
    "            'input_ids': encoding['input_ids'].flatten(),  \n",
    "            'attention_mask': encoding['attention_mask'].flatten(),  \n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.float32)   \n",
    "        }  \n",
    "\n",
    "# Creating the dataset  \n",
    "dataset = TextDataset(X, y, tokenizer)  \n",
    "\n",
    "# Split the dataset into train (90%) and test (10%)  \n",
    "train_size = int(0.9 * len(dataset))   \n",
    "test_size = len(dataset) - train_size   \n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])  \n",
    "\n",
    "# Create data loaders  \n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)  \n",
    "test_loader = DataLoader(test_dataset, batch_size=16)  \n",
    "\n",
    "# Define the neural network using nn.Module  \n",
    "class SpamDetectorNNWithBert(nn.Module):  \n",
    "    def __init__(self):  \n",
    "        super(SpamDetectorNNWithBert, self).__init__()  \n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased') \n",
    "        # self.bert = DistilBertModel.from_pretrained('distilbert-base-uncased') \n",
    "        self.linear = nn.Linear(768, 1)  # 768 is the output size from BERT  \n",
    "        # self.sigmoid = nn.Sigmoid()  \n",
    "\n",
    "    def forward(self, input_ids, attention_mask):  \n",
    "        # Get BERT embeddings  \n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)  \n",
    "        # Only take the output embeddings for the [CLS] token  \n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]  # Shape (batch_size, 768)  \n",
    "        # return self.sigmoid(self.linear(cls_output))  # Output shape (batch_size, 1)  \n",
    "        return self.linear(cls_output)  # Return logits directly\n",
    "\n",
    "# Create the model  \n",
    "model = SpamDetectorNNWithBert()  \n",
    "\n",
    "# Move model to CUDA if available  \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")    \n",
    "model.to(device)  \n",
    "\n",
    "# Choose loss function and optimizer  \n",
    "# criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)  # Lower learning rate for BERT  \n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Function to train the model  \n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10, accumulation_steps=4):  \n",
    "    model.train()  \n",
    "    scaler = GradScaler()  # Initialize the GradScaler for mixed precision \n",
    "    \n",
    "    for epoch in range(num_epochs):  \n",
    "        total_loss = 0  \n",
    "        for batch in tqdm(train_loader):  \n",
    "            input_ids = batch['input_ids'].to(device)  \n",
    "            attention_mask = batch['attention_mask'].to(device)  \n",
    "            labels = batch['labels'].to(device)  \n",
    "\n",
    "            # optimizer.zero_grad()  \n",
    "            # outputs = model(input_ids, attention_mask)  \n",
    "            # loss = criterion(outputs.view(-1), labels)  \n",
    "            # loss.backward()  \n",
    "            # optimizer.step()\n",
    "            \n",
    "            with autocast():  # Enable mixed precision  \n",
    "                # outputs = model(input_ids, attention_mask)  \n",
    "                # loss = criterion(outputs.view(-1), labels)  \n",
    "                logits = model(input_ids, attention_mask)\n",
    "                loss = criterion(logits.view(-1), labels.view(-1))\n",
    "\n",
    "            scaler.scale(loss).backward()  # Scale the loss and backpropagate  \n",
    "            scaler.step(optimizer)  # Update the weights  \n",
    "            scaler.update()  # Update the scale for the next iteration  \n",
    "\n",
    "            total_loss += loss.item()  \n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}],  Avg. Loss: {total_loss/len(train_loader):.4f}')  \n",
    "\n",
    "# Train the model\n",
    "# try:  \n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=2)\n",
    "# except (OutOfMemoryError):\n",
    "#     device = \"cpu\"\n",
    "#     model.to(device)\n",
    "#     train_model(model, train_loader, criterion, optimizer, num_epochs=2)\n",
    "\n",
    "# Evaluate the model  \n",
    "def evaluate_model(model, data_loader):  \n",
    "    model.eval()  \n",
    "    all_preds = []  \n",
    "    all_labels = []  \n",
    "    \n",
    "    with torch.no_grad():  \n",
    "        for batch in data_loader:  \n",
    "            input_ids = batch['input_ids'].to(device)  \n",
    "            attention_mask = batch['attention_mask'].to(device)  \n",
    "            labels = batch['labels'].to(device)  \n",
    "\n",
    "            outputs = model(input_ids, attention_mask)  \n",
    "            preds = (outputs.squeeze() > 0.5).float()  # Convert probabilities to binary predictions  \n",
    "            all_preds.extend(preds.cpu().numpy())  \n",
    "            all_labels.extend(labels.cpu().numpy())  \n",
    "    \n",
    "    return all_labels, all_preds  \n",
    "\n",
    "# Test the model  \n",
    "y_test, y_pred = evaluate_model(model, test_loader)  \n",
    "\n",
    "# Evaluate the model  \n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary Libraries\n",
    "import pandas as pd  \n",
    "import torch  \n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim \n",
    "from tqdm import tqdm \n",
    "from torch.utils.data import Dataset, DataLoader, random_split  \n",
    "from sklearn.metrics import classification_report, accuracy_score  \n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  Subject: naturally irresistible your corporate...      1\n",
      "1  Subject: the stock trading gunslinger  fanny i...      1\n",
      "2  Subject: unbelievable new homes made easy  im ...      1\n",
      "3  Subject: 4 color printing special  request add...      1\n",
      "4  Subject: do not have money , get software cds ...      1\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset  \n",
    "data = pd.read_csv(\"Data/FullDataset.csv\")  \n",
    "# See first 5 rows \n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dataset   \n",
    "X = data[\"text\"].values  \n",
    "y = data[\"label\"].values  \n",
    "\n",
    "# Load tokenizer for Bert  \n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class  \n",
    "class TextDataset(Dataset):  \n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):  \n",
    "        self.texts = texts  \n",
    "        self.labels = labels  \n",
    "        self.tokenizer = tokenizer  \n",
    "        self.max_length = max_length  # Max number of words in a senetence\n",
    "\n",
    "    def __len__(self):  \n",
    "        return len(self.texts)  \n",
    "\n",
    "    def __getitem__(self, idx):  \n",
    "        encoding = self.tokenizer.encode_plus(  # Encoding sentence\n",
    "            self.texts[idx],   \n",
    "            add_special_tokens=True,  # Contain Special tokens like [SEP]\n",
    "            max_length=self.max_length,   \n",
    "            padding='max_length',  # Fill letter sentece to have 128 word(token) with [PAD] \n",
    "            truncation=True,  # Cut big sentence to 128 token\n",
    "            return_tensors='pt'  \n",
    "        )  \n",
    "\n",
    "        # Return tensor inputs and label  \n",
    "        return {  \n",
    "            'input_ids': encoding['input_ids'].flatten(),  \n",
    "            'attention_mask': encoding['attention_mask'].flatten(),  \n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.float32)   \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset  \n",
    "dataset = TextDataset(X, y, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train (90%) and test (10%)  \n",
    "train_size = int(0.9 * len(dataset))   \n",
    "test_size = len(dataset) - train_size   \n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders  \n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)  \n",
    "test_loader = DataLoader(test_dataset, batch_size=16)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network using nn.Module  \n",
    "class SpamDetectorNNWithBert(nn.Module):  \n",
    "    def __init__(self):  \n",
    "        super(SpamDetectorNNWithBert, self).__init__()  \n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased') \n",
    "        self.linear = nn.Linear(768, 1)  # 768 is the output size from BERT  \n",
    "\n",
    "    def forward(self, input_ids, attention_mask):  \n",
    "        # Get BERT embeddings  \n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)  \n",
    "        # Only take the output embeddings for the [CLS] token  \n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]  # Get the CLS token output  \n",
    "        return self.linear(cls_output)  # Return logits directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model  \n",
    "model = SpamDetectorNNWithBert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpamDetectorNNWithBert(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move model to CUDA if available  \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")    \n",
    "model.to(device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose loss function and optimizer  \n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model  \n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):  \n",
    "    model.train()  \n",
    "    # scaler = GradScaler()  # Initialize the GradScaler for mixed precision \n",
    "    \n",
    "    for epoch in range(num_epochs):  \n",
    "        total_loss = 0  \n",
    "        for batch in tqdm(train_loader):  \n",
    "            input_ids = batch['input_ids'].to(device)  \n",
    "            attention_mask = batch['attention_mask'].to(device)  \n",
    "            labels = batch['labels'].to(device)  \n",
    "\n",
    "            optimizer.zero_grad()  \n",
    "            logits = model(input_ids, attention_mask)\n",
    "            loss = criterion(logits.view(-1), labels.view(-1))\n",
    "            loss.backward()  \n",
    "            optimizer.step() \n",
    "\n",
    "            total_loss += loss.item()  \n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}],  Avg. Loss: {total_loss/len(train_loader):.4f}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9251 [00:00<?, ?it/s]c:\\Users\\tasha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "100%|██████████| 9251/9251 [2:27:48<00:00,  1.04it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2],  Avg. Loss: 0.0382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9251/9251 [4:00:10<00:00,  1.56s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2],  Avg. Loss: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, criterion, optimizer, num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model  \n",
    "def evaluate_model(model, data_loader):  \n",
    "    model.eval()  \n",
    "    all_preds = []  \n",
    "    all_labels = []  \n",
    "    \n",
    "    with torch.inference_mode():  \n",
    "        for batch in data_loader:  \n",
    "            input_ids = batch['input_ids'].to(device)  \n",
    "            attention_mask = batch['attention_mask'].to(device)  \n",
    "            labels = batch['labels'].to(device)  \n",
    "\n",
    "            outputs = model(input_ids, attention_mask)  \n",
    "            preds = (outputs.squeeze() > 0.5).float()  # Convert probabilities to binary predictions  \n",
    "            all_preds.extend(preds.cpu().numpy())  \n",
    "            all_labels.extend(labels.cpu().numpy())  \n",
    "    \n",
    "    return all_labels, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model  \n",
    "y_test, y_pred = evaluate_model(model, test_loader)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9937982610810482\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      8210\n",
      "         1.0       0.99      0.99      0.99      8237\n",
      "\n",
      "    accuracy                           0.99     16447\n",
      "   macro avg       0.99      0.99      0.99     16447\n",
      "weighted avg       0.99      0.99      0.99     16447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model  \n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "from pathlib import Path\n",
    "\n",
    "Path(\"Saved_model\").mkdir(exist_ok=True)\n",
    "# Save model's weight\n",
    "torch.save(model.state_dict(), \"Saved_model/Spam_Email_Detector_DeepNLP_BERT_PyTorch_Weight.pt\")\n",
    "# Save whole model with structure\n",
    "torch.save(model, \"Saved_model/Spam_Email_Detector_DeepNLP_BERT_PyTorch_WithStructure.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in below cells, you can load saved model and predict with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model Structure and load saved weights\n",
    "class SpamDetectorNNWithBert(nn.Module):  \n",
    "    def __init__(self):  \n",
    "        super(SpamDetectorNNWithBert, self).__init__()  \n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased') \n",
    "        self.linear = nn.Linear(768, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):  \n",
    "        # Get BERT embeddings  \n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)  \n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
    "        return self.linear(cls_output)\n",
    "    \n",
    "model = SpamDetectorNNWithBert()\n",
    "model.load_state_dict(torch.load(\"Saved_model/Spam_Email_Detector_DeepNLP_BERT_PyTorch_Weight.pt\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load whole model with structure\n",
    "model = torch.load(\"Saved_model/Spam_Email_Detector_DeepNLP_BERT_PyTorch_WithStructure.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict With model\n",
    "encoding = tokenizer.encode_plus(\n",
    "text,   # Replace with your text data\n",
    "add_special_tokens=True,\n",
    "max_length=128,   \n",
    "padding='max_length',\n",
    "truncation=True,\n",
    "return_tensors='pt'  \n",
    ")  \n",
    "   \n",
    "model.eval()  \n",
    "with torch.inference_mode():  \n",
    "    outputs = model(encoding['input_ids'].to(device), encoding['attention_mask'].to(device))  \n",
    "    preds = (outputs.squeeze() > 0.5).float()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
