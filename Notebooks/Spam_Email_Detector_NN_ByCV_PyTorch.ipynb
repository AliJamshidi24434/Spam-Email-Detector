{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Email Detector with Neural Network and CountVectorizer\n",
    "## with ~98% Accuracy on 164K email sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary Libraries\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import torch  \n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  Subject: naturally irresistible your corporate...      1\n",
      "1  Subject: the stock trading gunslinger  fanny i...      1\n",
      "2  Subject: unbelievable new homes made easy  im ...      1\n",
      "3  Subject: 4 color printing special  request add...      1\n",
      "4  Subject: do not have money , get software cds ...      1\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset  \n",
    "data = pd.read_csv(\"Data/FullDataset.csv\") \n",
    "# See first 5 rows \n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dataset  \n",
    "\n",
    "# Split the data into features and labels  \n",
    "X = data[\"text\"].values  \n",
    "y = data[\"label\"].values\n",
    "# Split the data into train and test sets  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text vectorization using CountVectorizer with limited features \n",
    "# Convert text data to numerical data using CountVectorizer (Count each word from whole vocabulary in each sample) \n",
    "vectorizer = CountVectorizer(max_features=10000)  # Limit to top 10,000 features for impact effect on memory\n",
    "# Fit train data to catch vocabulary of whole words AND transform them to numerical data\n",
    "X_train_counts = vectorizer.fit_transform(X_train) \n",
    "# transform test data to numerical data based on train data vocabulary\n",
    "X_test_counts = vectorizer.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasha\\AppData\\Local\\Temp\\ipykernel_18724\\4293223180.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:277.)\n",
      "  X_train_tensor = torch.sparse.FloatTensor(torch.LongTensor(X_train_counts.nonzero()),  # get the integer indices of the non-zero elements as LongTensor\n",
      "C:\\Users\\tasha\\AppData\\Local\\Temp\\ipykernel_18724\\4293223180.py:2: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:623.)\n",
      "  X_train_tensor = torch.sparse.FloatTensor(torch.LongTensor(X_train_counts.nonzero()),  # get the integer indices of the non-zero elements as LongTensor\n"
     ]
    }
   ],
   "source": [
    "# Convert the sparse matrix to a PyTorch sparse tensor  \n",
    "X_train_tensor = torch.sparse.FloatTensor(torch.LongTensor(X_train_counts.nonzero()),  # get the integer indices of the non-zero elements as LongTensor\n",
    "                                           torch.FloatTensor(X_train_counts.data),  # get real data of indices of the non-zero elements as FloatTensor\n",
    "                                           torch.Size(X_train_counts.shape))  # Set shape size of sparse vector as tensor size\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)  # we need to convert y data (0 and 1) to float32, to compatible with train tensor\n",
    "X_test_tensor = torch.sparse.FloatTensor(torch.LongTensor(X_test_counts.nonzero()),   \n",
    "                                          torch.FloatTensor(X_test_counts.data),   \n",
    "                                          torch.Size(X_test_counts.shape))  \n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network class  \n",
    "class SpamDetectorNNByCV(nn.Module):  \n",
    "    def __init__(self, input_size):  \n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 64)  \n",
    "        self.layer2 = nn.Linear(64, 32)  \n",
    "        self.layer3 = nn.Linear(32, 1)  \n",
    "        self.sigmoid = nn.Sigmoid() # Scale output between 0 and 1\n",
    "\n",
    "    def forward(self, x):  \n",
    "        # # use ReLU to replace negative values with 0\n",
    "        # x = torch.relu(self.fc1(x))  \n",
    "        # x = torch.relu(self.fc2(x))  \n",
    "        # x = self.sigmoid(self.fc3(x))  \n",
    "        # return x \n",
    "        \n",
    "        # Optimized Retrun\n",
    "        return self.sigmoid(self.layer3(torch.relu(self.layer2(torch.relu(self.layer1(x))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model  \n",
    "input_size = X_train_tensor.size(1)  # feature size of train data (0 -> number of samples, 1 -> feature size)\n",
    "model = SpamDetectorNNByCV(input_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and optimizer  \n",
    "criterion = nn.BCELoss()  # for Binary Classification (1 -> spam, 0 -> ham)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40], Loss: 0.6935\n",
      "Epoch [2/40], Loss: 0.6667\n",
      "Epoch [3/40], Loss: 0.6401\n",
      "Epoch [4/40], Loss: 0.6107\n",
      "Epoch [5/40], Loss: 0.5785\n",
      "Epoch [6/40], Loss: 0.5467\n",
      "Epoch [7/40], Loss: 0.5156\n",
      "Epoch [8/40], Loss: 0.4847\n",
      "Epoch [9/40], Loss: 0.4549\n",
      "Epoch [10/40], Loss: 0.4271\n",
      "Epoch [11/40], Loss: 0.4010\n",
      "Epoch [12/40], Loss: 0.3773\n",
      "Epoch [13/40], Loss: 0.3551\n",
      "Epoch [14/40], Loss: 0.3345\n",
      "Epoch [15/40], Loss: 0.3153\n",
      "Epoch [16/40], Loss: 0.2974\n",
      "Epoch [17/40], Loss: 0.2813\n",
      "Epoch [18/40], Loss: 0.2660\n",
      "Epoch [19/40], Loss: 0.2518\n",
      "Epoch [20/40], Loss: 0.2386\n",
      "Epoch [21/40], Loss: 0.2263\n",
      "Epoch [22/40], Loss: 0.2149\n",
      "Epoch [23/40], Loss: 0.2042\n",
      "Epoch [24/40], Loss: 0.1943\n",
      "Epoch [25/40], Loss: 0.1857\n",
      "Epoch [26/40], Loss: 0.1770\n",
      "Epoch [27/40], Loss: 0.1689\n",
      "Epoch [28/40], Loss: 0.1613\n",
      "Epoch [29/40], Loss: 0.1542\n",
      "Epoch [30/40], Loss: 0.1475\n",
      "Epoch [31/40], Loss: 0.1413\n",
      "Epoch [32/40], Loss: 0.1354\n",
      "Epoch [33/40], Loss: 0.1298\n",
      "Epoch [34/40], Loss: 0.1246\n",
      "Epoch [35/40], Loss: 0.1197\n",
      "Epoch [36/40], Loss: 0.1150\n",
      "Epoch [37/40], Loss: 0.1107\n",
      "Epoch [38/40], Loss: 0.1066\n",
      "Epoch [39/40], Loss: 0.1027\n",
      "Epoch [40/40], Loss: 0.0990\n"
     ]
    }
   ],
   "source": [
    "# Train the model  \n",
    "for epoch in range(40):  \n",
    "    model.train()  \n",
    "    optimizer.zero_grad()  \n",
    "    \n",
    "    # Need to convert sparse tensor to dense tensor for training  \n",
    "    outputs = model(X_train_tensor.to_dense())  \n",
    "    \n",
    "    loss = criterion(outputs.squeeze(), y_train_tensor)  \n",
    "    loss.backward()  \n",
    "    optimizer.step()  \n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{40}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model  \n",
    "model.eval()  \n",
    "with torch.inference_mode():  \n",
    "    test_outputs = model(X_test_tensor.to_dense())  \n",
    "    predicted = (test_outputs.squeeze() > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9789012859879002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     16395\n",
      "           1       0.98      0.98      0.98     16498\n",
      "\n",
      "    accuracy                           0.98     32893\n",
      "   macro avg       0.98      0.98      0.98     32893\n",
      "weighted avg       0.98      0.98      0.98     32893\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model  \n",
    "print(\"Accuracy:\", accuracy_score(y_test, predicted.numpy()))  \n",
    "print(classification_report(y_test, predicted.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "from pathlib import Path\n",
    "\n",
    "Path(\"Saved_model\").mkdir(exist_ok=True)\n",
    "# Save model's weight\n",
    "torch.save(model.state_dict(), \"Saved_model/Spam_Email_Detector_NN_ByCV_PyTorch_Weight.pt\")\n",
    "# Save whole model with structure\n",
    "torch.save(model, \"Saved_model/Spam_Email_Detector_NN_ByCV_PyTorch_WithStructure.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in below cells, you can load saved model and predict with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model Structure and load saved weights\n",
    "class SpamDetectorNNByCV(nn.Module):  \n",
    "    def __init__(self, input_size):  \n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 64)  \n",
    "        self.layer2 = nn.Linear(64, 32)  \n",
    "        self.layer3 = nn.Linear(32, 1)  \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):  \n",
    "        return self.sigmoid(self.layer3(torch.relu(self.layer2(torch.relu(self.layer1(x))))))\n",
    "    \n",
    "model = SpamDetectorNNByCV(input_size) # Replace with you input_size data\n",
    "model.load_state_dict(torch.load(\"Saved_model/Spam_Email_Detector_NN_ByCV_PyTorch_Weight.pt\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load whole model with structure\n",
    "model = torch.load(\"Saved_model/Spam_Email_Detector_NN_ByCV_PyTorch_WithStructure.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict With model\n",
    "model.eval()  \n",
    "with torch.inference_mode():  \n",
    "    test_outputs = model(X_test_tensor.to_dense())  # Replace with your X_test_tensor data\n",
    "    predicted = (test_outputs.squeeze() > 0.5).float()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
